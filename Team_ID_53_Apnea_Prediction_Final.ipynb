{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Notebook to Google Drive\n",
        "Note to instructor: You need to mount the google drive to your drive to run this"
      ],
      "metadata": {
        "id": "dlv6knX04FiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "KTsiwGQdZXIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d5a335-771d-4c95-b331-5fd8b53a23d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "u-gD-VRSZcIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb65fb65-3e19-4769-b27c-9237d556d3b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sfk8Zrul_E8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "371d11be-caca-41dd-f6e5-b7792578d255"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to Final Colab Notebook: https://colab.research.google.com/drive/1551qz_-RaXk9tXLSNWeb0LAbIuFDmk2_?usp=sharing\n",
        "\n",
        "Link to GitHub: https://github.com/sakethn99/CS598_SleepApneaPrediction_Project/tree/master\n",
        "\n",
        "Link to Video: https://drive.google.com/file/d/1-XRtniXxWfvJPP9yt_wCX92i0ZRQwCuL/view?usp=sharing\n",
        "\n",
        "Link to CS_598_Proj Folder: https://drive.google.com/drive/folders/1hk9RS3LxWQnvgyY95T20B1GP08pbCqEE?usp=sharing, this folder contains links to our data processing files and a sample of the datafiles\n",
        "\n",
        "Link to Data: https://drive.google.com/drive/folders/1aNS4aKUYo7HiJCyOTdjNxhxOlPP-WbDB?usp=drive_link, this folder contains\n",
        "the entire dataset we used to train the model\n",
        "\n",
        "#### Environment Setup\n",
        "Please refer to the github link above for setup instructions"
      ],
      "metadata": {
        "id": "fO4j8IQDJNka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n"
      ],
      "metadata": {
        "id": "UvwLb5y9Jzpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Background of the problem\n",
        "  * what type of problem: disease/readmission/mortality prediction,  feature engineeing, data processing, etc\n",
        "  \n",
        "        - Sleep apnea is a sleeping disorder characterized by recurring events of obstruction, such as sleep fragmentation, sporadic oxygen desaturation (hypoxemia), and excessive carbon dioxide in the bloodstream (hypercapnia). Childhood sleep apnea often goes undiagnosed and is estimated to effect one to five percent of children with peak prevelance between the ages 2 and 8 (Fayyaz, 1). Generally, the sleep data is different between children and adults and the symptoms of sleep apnea in children are scarce and require more attention, making the diagnosis more difficult.\n",
        "\n",
        "  * what is the importance/meaning of solving the problem\n",
        "      - In order to diagnose sleep apnea, families often have to spend a lot of time/money to travel to clinics. If sleep apnea is not treated in a timely manner could lead to physical and mental health issues. Solving this problem would reduce the need for Polysomnography, which collects biological signals during sleep. Polysomnography is considered effective but is very costly and intrusive. A sleep apnea detector will inform people earlier if signs of sleep apnea are present and may encourage people to get a professional study done. This method will reduce the cost and time people need to spend studying their childs sleep.\n",
        "      \n",
        "      - The method proposed in this paper can predict sleep apnea using just two features (ECG/SP02), which can be collected at home. This saves time and makes diagnosis/treatment possible for more people.\n",
        "\n",
        "  * what is the difficulty of the problem\n",
        "      - Access to at-home testing is not available for children.\n",
        "      - Current models/work are not tailored towards the pediatric case.\n",
        "      - This may not be considered a real diagnosis, but it should encourage people to go see a doctor if signs are prevelant.\n",
        "\n",
        "  * the state of the art methods and effectiveness.\n",
        "      - Polysomnography is the current medical procedure to diagnose sleep apnea.Generally this is considered effective, but there is high-cost, complexity (many different signals need to be collected), and is expensive.\n",
        "      - This paper uses transformers to try and predict whether or not a child has sleep apnea.\n",
        "\n",
        "*   Paper explanation\n",
        "  * what did the paper propose\n",
        "      - The paper targets the disparity between at-home sleep apnea testing tools between children and adults. While these tools are widely present for adults, they are not so prevelant for children. This study aims to narrow the gap between children and adults by using a machine learning-based model for detecting apnea events from commonly collected sleep signals.\n",
        "\n",
        "  * what is the innovations of the method\n",
        "      - The innovation this method brings is that it bridges the gap between adult and children sleep apnea detection tools, while out-performing state-of-the-art methods. Additionally, this method shows that using two signals that are easier to collect at home (ECG and SpO2) can achieve competitive results, addressing concerns with collecting children's sleep signals outside the clinic.\n",
        "\n",
        "  * how well the proposed method work (in its own metrics)\n",
        "      - The authors chose four state-of-the-art studies on adult sleep apnea with various different models to compare to (CNN, SE-MSCNN, CNN+LSTM, Hybrid Transfomer). The authors method consisted of a customized pipeline based on a generic transformer architecture. The model compares F1 and AUROC scores. The authors model outscores all the baselines and outperforms the other models by age group. (Table 3 and Table 5)\n",
        "\n",
        "      ![Table 3](https://drive.google.com/uc?export=view&id=1LM0g3kAmPRawpcrUWcYp_t74sgq7ahrm)\n",
        "\n",
        "      ![Figure 2](https://drive.google.com/uc?export=view&id=1vkw7LHIO-fFxwT2oYSUglwEYoRfm9Ix7)\n",
        "      \n",
        "  * what is the contribution to the research regime\n",
        "      - This papers contribution is to help diagnose sleep apnea in children by providing an algorithm that can potentially be packaged into a home testing kit, so that families do not have to spend money to travel to hospitals. This represents a significant advancement in childhood sleep apnea diagnosis.\n"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "Hypothesis 1: It is possible to detect Obstructive Sleep apnea hypopnea Syndrome (OSAHS) in pediatric patients with PSG-level performance in adults\n",
        "\n",
        "Experiments we will run:\n",
        "Parse the CHAT dataset using preprocessing data loading scripts and feed this data into a transformer model using the multi-head attention model. Compare results to the paper\n",
        "Try changing the multi-head attention to single-head attention and compare the results\n",
        "Change the attention mechanism from dot product to cosine similarity or Gaussian based and compare the results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "fSzQQOG9SBva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import  packages you need\n",
        "!python --version\n",
        "!pip list\n",
        "#tensorflow_addons-0.23.0\n",
        "\n",
        "#tensorflow                       2.15.0\n",
        "#keras                            2.15.0\n"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06fa0cc8-ebbe-4bf7-95c9-ae75e8c70fb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.9.5\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.16\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "annotated-types                  0.6.0\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array_record                     0.5.1\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.1.0\n",
            "attrs                            23.2.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.14.0\n",
            "backcall                         0.2.0\n",
            "beautifulsoup4                   4.12.3\n",
            "bidict                           0.23.1\n",
            "bigframes                        1.4.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.3.4\n",
            "bqplot                           0.12.43\n",
            "branca                           0.7.2\n",
            "build                            1.2.1\n",
            "CacheControl                     0.14.0\n",
            "cachetools                       5.3.3\n",
            "catalogue                        2.0.10\n",
            "certifi                          2024.2.2\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.86\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpathlib                     0.16.0\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.9\n",
            "cmdstanpy                        1.2.2\n",
            "colorcet                         3.1.0\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.4\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.1\n",
            "cryptography                     42.0.5\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda12x                     12.2.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.4\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.10\n",
            "dask                             2023.8.1\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.2.0\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.4\n",
            "dm-tree                          0.1.8\n",
            "docstring_parser                 0.16\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.10.2\n",
            "earthengine-api                  0.1.400\n",
            "easydict                         1.13\n",
            "ecos                             2.0.13\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.7.1\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.7.0\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.2.1\n",
            "fastai                           2.7.15\n",
            "fastcore                         1.5.33\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.19.1\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.14.0\n",
            "fiona                            1.9.6\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      24.3.25\n",
            "flax                             0.8.3\n",
            "folium                           0.14.0\n",
            "fonttools                        4.51.0\n",
            "frozendict                       2.4.2\n",
            "frozenlist                       1.4.1\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.5.4\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.6.4\n",
            "gdown                            5.1.0\n",
            "geemap                           0.32.0\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.6.2\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.27.0\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.2.0\n",
            "google-cloud-aiplatform          1.48.0\n",
            "google-cloud-bigquery            3.21.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.24.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.15.0\n",
            "google-cloud-language            2.13.3\n",
            "google-cloud-resource-manager    1.12.3\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.5.2\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.7.0\n",
            "googleapis-common-protos         1.63.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.3\n",
            "greenlet                         3.0.3\n",
            "grpc-google-iam-v1               0.13.0\n",
            "grpcio                           1.63.0\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          6.0.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.47\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "huggingface-hub                  0.20.3\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   8.0.0\n",
            "idna                             3.7\n",
            "imageio                          2.31.6\n",
            "imageio-ffmpeg                   0.4.9\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib_metadata               7.1.0\n",
            "importlib_resources              6.4.0\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "intel-openmp                     2023.2.4\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.2\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.2.0\n",
            "jax                              0.4.26\n",
            "jaxlib                           0.4.26+cuda12.cudnn89\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.3\n",
            "joblib                           1.4.0\n",
            "jsonpickle                       3.0.4\n",
            "jsonschema                       4.19.2\n",
            "jsonschema-specifications        2023.12.1\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.7.2\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab_widgets               3.0.10\n",
            "kaggle                           1.6.12\n",
            "kagglehub                        0.2.4\n",
            "keras                            2.15.0\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.4.0\n",
            "language_data                    1.2.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.4\n",
            "libclang                         18.1.1\n",
            "librosa                          0.10.1\n",
            "lightgbm                         4.1.0\n",
            "linkify-it-py                    2.0.3\n",
            "llvmlite                         0.41.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.4\n",
            "malloy                           2023.1067\n",
            "marisa-trie                      1.1.0\n",
            "Markdown                         3.6\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.5\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.7\n",
            "matplotlib-venn                  0.11.10\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.8\n",
            "multidict                        6.0.5\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.0.0\n",
            "nbclient                         0.10.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.10.4\n",
            "nest-asyncio                     1.6.0\n",
            "networkx                         3.3\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.4\n",
            "numba                            0.58.1\n",
            "numexpr                          2.10.0\n",
            "numpy                            1.25.2\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.9.0.80\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.2.2\n",
            "orbax-checkpoint                 0.4.4\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        24.0\n",
            "pandas                           2.0.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.19.2\n",
            "pandas-stubs                     2.0.3.230814\n",
            "pandocfilters                    1.5.1\n",
            "panel                            1.3.8\n",
            "param                            2.1.0\n",
            "parso                            0.8.4\n",
            "parsy                            2.1\n",
            "partd                            1.4.1\n",
            "pathlib                          1.0.1\n",
            "patsy                            0.5.6\n",
            "peewee                           3.17.3\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     4.2.1\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.5.0\n",
            "polars                           0.20.2\n",
            "pooch                            1.8.1\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.10.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus_client                0.20.0\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.43\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.23.0\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          14.0.2\n",
            "pyarrow-hotfix                   0.6\n",
            "pyasn1                           0.6.0\n",
            "pyasn1_modules                   0.4.0\n",
            "pycocotools                      2.0.7\n",
            "pycparser                        2.22\n",
            "pydantic                         2.7.1\n",
            "pydantic_core                    2.18.2\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.4\n",
            "pygame                           2.5.2\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.10.4\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        24.1.0\n",
            "pyparsing                        3.1.2\n",
            "pyperclip                        1.8.2\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.1.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.18.6\n",
            "pytest                           7.4.4\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.1.1\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.4\n",
            "python-utils                     3.8.2\n",
            "pytz                             2023.4\n",
            "pyviz_comms                      3.0.2\n",
            "PyWavelets                       1.6.0\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            24.0.1\n",
            "qdldl                            0.1.7.post2\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.35.0\n",
            "regex                            2023.12.25\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.9.0\n",
            "rich                             13.7.1\n",
            "rpds-py                          0.18.0\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.3\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.4\n",
            "scooby                           0.9.2\n",
            "scs                              3.2.4.post1\n",
            "seaborn                          0.13.1\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.3\n",
            "sentencepiece                    0.1.99\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.4\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.4.0\n",
            "sniffio                          1.3.1\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.7.4\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.8\n",
            "sphinxcontrib-devhelp            1.0.6\n",
            "sphinxcontrib-htmlhelp           2.0.5\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.7\n",
            "sphinxcontrib-serializinghtml    1.1.10\n",
            "SQLAlchemy                       2.0.29\n",
            "sqlglot                          20.11.0\n",
            "sqlparse                         0.5.0\n",
            "srsly                            2.4.8\n",
            "stanio                           0.5.0\n",
            "statsmodels                      0.14.2\n",
            "StrEnum                          0.4.15\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.12.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.2.3\n",
            "tensorboard                      2.15.2\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.15.0\n",
            "tensorflow-datasets              4.9.4\n",
            "tensorflow-estimator             2.15.0\n",
            "tensorflow-gcs-config            2.15.0\n",
            "tensorflow-hub                   0.16.1\n",
            "tensorflow-io-gcs-filesystem     0.37.0\n",
            "tensorflow-metadata              1.15.0\n",
            "tensorflow-probability           0.23.0\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.1\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf_keras                         2.15.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.2.3\n",
            "threadpoolctl                    3.5.0\n",
            "tifffile                         2024.4.24\n",
            "tinycss2                         1.3.0\n",
            "tokenizers                       0.19.1\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.1\n",
            "torch                            2.2.1+cu121\n",
            "torchaudio                       2.2.1+cu121\n",
            "torchdata                        0.7.1\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.17.1\n",
            "torchvision                      0.17.1+cu121\n",
            "tornado                          6.3.3\n",
            "tqdm                             4.66.2\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.40.1\n",
            "triton                           2.2.0\n",
            "tweepy                           4.14.0\n",
            "typer                            0.9.4\n",
            "types-pytz                       2024.1.0.20240417\n",
            "types-setuptools                 69.5.0.20240423\n",
            "typing_extensions                4.11.0\n",
            "tzdata                           2024.1\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.3\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.13\n",
            "weasel                           0.3.4\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.8.0\n",
            "Werkzeug                         3.0.2\n",
            "wheel                            0.43.0\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.3\n",
            "wrapt                            1.14.1\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.7.0\n",
            "xgboost                          2.0.3\n",
            "xlrd                             2.0.1\n",
            "xyzservices                      2024.4.0\n",
            "yarl                             1.9.4\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.38\n",
            "zict                             3.0.0\n",
            "zipp                             3.18.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The python version we used for this project is python 3.10.12. All of the libraries that we used are the python libraries that come preinstalled with Google Colab, as listed above. The only library we installed is the tensorflow_addons library (v0.23.0)"
      ],
      "metadata": {
        "id": "KY8LIrv4SG7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "\n"
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two datasets that were used in the original paper, the CHAT dataset and NCH dataset. The CHAT dataset is much smaller and has a greater focus on the children demographic, so we have started the project with this dataset, so we have started with this due to the magnitude of time required for the pre-processing.  **We only used the CHAT dataset, as parsing the NCH dataset eould require significantly more computational resources as it is over 2 TB of data.**\n",
        "\n",
        "\n",
        "\n",
        "### Source\n",
        "#### CHAT Dataset\n",
        "\n",
        "The CHAT dataset is a multi-center, single-blind, randomized, controled trial to analyze the the effectiveness of removing adenois and tonsils in children with moderate objstructed apnea.  The sleep was assessed with a full PSG and the scoring completed and the Brigham and Women's hospital.  \n",
        "\n",
        "To access the data, we had to put in a request with the National Sleep Resarch Resource (NSRR).  We were then granted access to download the data.  The data was able to be downloaded using a Ruby gem (Github link to Ruby gem installer: https://github.com/nsrr/nsrr-gem/tree/master) which automated the process of downloading.  Based on what the data that the paper had used, we downloaded the \"polysomnography\" datasets which is EEG time series data that were in \"edf\" format and the associated xml annotations from NSRR.\n",
        "\n",
        "![EEG](https://drive.google.com/uc?export=view&id=1vO_LrRtHqVODzLoQk9_aXSFC752KD24r)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tHOL5iUgvlux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistics\n",
        "\n",
        "1,447 children had the PSG screening an 464 were randomized to treatment.\n",
        "\n",
        "||CHAT||\n",
        "|----|---|-|\n",
        "|Number of Patients||453|\n",
        "|Number of Sleep Studies||453|\n",
        "|Sex|Male|219|\n",
        "||Female|234|\n",
        "|Race|Asian|8|\n",
        "||Black|252|\n",
        "||While|161|\n",
        "||Other|32|\n",
        "\n",
        "---\n",
        "\n",
        "#### Label Distribution\n",
        "|Event|CHAT|\n",
        "|--|--|\n",
        "|Oxygen Desaturation| 6,5006|\n",
        "|Oximeter Event| 9,864|\n",
        "|EEG arousal|\n",
        "||Respriatory Events||\n",
        "|Hypopnea|15,871|\n",
        "|Obstructive Hypopnea|\n",
        "|Obstructive apnea|7,075\n",
        "|Central apnea|3,656|\n",
        "|Mixed apnea|\n",
        "||Sleep Stages||\n",
        "|Wake|10,282|\n",
        "|N1|13,578|\n",
        "|N2|19,985|\n",
        "|N3|9.981|\n",
        "|REM|3,283|\n",
        "\n",
        "#### Validation\n",
        "The validation technique used in the study is the K-fold cross-validation.  Due to the fact that the patient recording have shared features, the model has a tendency to learn characteristics of patient recordings, instead of focusing on the fundamental features.  Cross-validation needs to be performed on folds where there is no shared patient between them.  Meaning all epcoch from all sleep studies of a patient should end up in one fold.  To get around this, authors fot he original paper proposed the stratified K-Fold Cross Validation Algorithm shown below\n",
        "\n",
        "**Algorithm: K-Fold Validation**\n",
        "\n",
        "**Input:** $\\{P_n\\}_{n=1}^N$  \n",
        "**Output:** $\\{\\text{fold}_f\\}_{n=1}^K$\n",
        "\n",
        "1. For $n = 1$ to $N$:\n",
        "   - Initialize $P_i.\\text{score} = 0$\n",
        "   - For $m = 1$ to $M_n$:\n",
        "     - For $l = 1$ to $L_{n,m}$:\n",
        "       - Update $P_i.\\text{score} += \\text{length}(E_{k_{i,j}})$\n",
        "\n",
        "2. Sort patients by score into $\\text{score sorted list}$\n",
        "3. For $i = 1$ to $N$:\n",
        "   - Calculate $f = i \\mod K$\n",
        "   - Assign $\\text{fold}_f = \\text{score sorted list}[i]$"
      ],
      "metadata": {
        "id": "XdhiTrIJI_EZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Process\n",
        "\n",
        "To prepare the data for processing, we had to complete the following steps\n",
        "\n",
        "\n",
        "In addition to the raw .edf data, the annotation files had to be matched to the raw data samples.  In this case, we used the \"nsrr\" notations and had to convert the .xml files to .tsv (tab separated value) to be compatible with the pre-processing script provided with the paper.\n",
        "\n",
        "Once we have the .tsv and .edf files we can begin to run the preprocesing script.  \n",
        "\n",
        "The script can be found in the following link: [Preprocessing Script](https://colab.research.google.com/drive/1DmRCJH-16TAyV5O-EYAY9ltdUGdaABNj?usp=sharing)\n",
        "\n",
        "The task of the preprocessing script is to extract the labels for the various detetected sleep events and assign integer values for easier ingestion into the model.  The events include:\n",
        "* Apnea (obstructive and central) assigned a label of 2\n",
        "* Hypopnea assigned a label of 1\n",
        "* Wake events assigned a label of 10\n",
        "* Normal sleep assigned a label of 0\n",
        "\n",
        "The script used the MNE-Python library to parse the EDT data which is specifically designed to work with EEG data.\n",
        "\n",
        "Once the data is parsed, it is saved in a compressed numpy array file, ready to be used by the model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jIoaaJ2j54Bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataloader\n",
        "\n",
        "In addition to the Preprocessing script, the code from the paper also provided a Dataloader.\n",
        "\n",
        "The purspose of the data loader is to extract the RRI information and to load the data for the model, specifically handling the folding strategy based on the number of respiratory events.\n",
        "\n",
        "The dataloading script is in the [CHAT Dataloader Link](https://colab.research.google.com/drive/1O4Icb9z_kpP7Iq1J-Ib-x8p-TmQ8ddL9?authuser=1) CHAT_Processing.ipynb file. With access to the google drive, all of the folder locations are defined, so the dataloader can be run from your local drive.\n"
      ],
      "metadata": {
        "id": "knmrxK33MaiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XzVUQS0CHry0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer model"
      ],
      "metadata": {
        "id": "Lo8HJuZRPLJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "DnRlxhQgZ0pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707aa26d-17c4-466f-e10d-ff81af52df1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from keras import Model\n",
        "from keras.activations import sigmoid, relu\n",
        "from keras.layers import Dense, Dropout, Reshape, LayerNormalization, MultiHeadAttention, Add, Flatten, Input, Layer, \\\n",
        "    GlobalAveragePooling1D, AveragePooling1D, Concatenate, SeparableConvolution1D, Conv1D\n",
        "from keras.regularizers import L2\n",
        "\n",
        "\n",
        "\n",
        "class Patches(Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, input):\n",
        "        input = input[:, tf.newaxis, :, :]\n",
        "        batch_size = tf.shape(input)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=input,\n",
        "            sizes=[1, 1, self.patch_size, 1],\n",
        "            strides=[1, 1, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches,\n",
        "                             [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "\n",
        "class PatchEncoder(Layer):\n",
        "    def __init__(self, num_patches, projection_dim, l2_weight):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.projection_dim = projection_dim\n",
        "        self.l2_weight = l2_weight\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = Dense(units=projection_dim, kernel_regularizer=L2(l2_weight),\n",
        "                                bias_regularizer=L2(l2_weight))\n",
        "        self.position_embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) # + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate, l2_weight):\n",
        "    for _, units in enumerate(hidden_units):\n",
        "        x = Dense(units, activation=None, kernel_regularizer=L2(l2_weight), bias_regularizer=L2(l2_weight))(x)\n",
        "        x = tf.nn.gelu(x)\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def create_transformer_model(input_shape, num_patches,\n",
        "                             projection_dim, transformer_layers,\n",
        "                             num_heads, transformer_units, mlp_head_units,\n",
        "                             num_classes, drop_out, reg, l2_weight, demographic=False):\n",
        "    if reg:\n",
        "        activation = None\n",
        "    else:\n",
        "        activation = 'sigmoid'\n",
        "    inputs = Input(shape=input_shape)\n",
        "    patch_size = input_shape[0] / num_patches\n",
        "    if demographic:\n",
        "        normalized_inputs = tfa.layers.InstanceNormalization(axis=-1, epsilon=1e-6, center=False, scale=False,\n",
        "                                                             beta_initializer=\"glorot_uniform\",\n",
        "                                                             gamma_initializer=\"glorot_uniform\")(inputs[:,:,:-1])\n",
        "        demo = inputs[:, :12, -1]\n",
        "\n",
        "    else:\n",
        "        normalized_inputs = tfa.layers.InstanceNormalization(axis=-1, epsilon=1e-6, center=False, scale=False,\n",
        "                                                             beta_initializer=\"glorot_uniform\",\n",
        "                                                             gamma_initializer=\"glorot_uniform\")(inputs)\n",
        "\n",
        "    # patches = Reshape((num_patches, -1))(normalized_inputs)\n",
        "    patches = Patches(patch_size=patch_size)(normalized_inputs)\n",
        "    encoded_patches = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim, l2_weight=l2_weight)(patches)\n",
        "    for i in range(transformer_layers):\n",
        "        x1 = encoded_patches # LayerNormalization(epsilon=1e-6)(encoded_patches) # TODO\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=drop_out, kernel_regularizer=L2(l2_weight),  # i *\n",
        "            bias_regularizer=L2(l2_weight))(x1, x1)\n",
        "        x2 = Add()([attention_output, encoded_patches])\n",
        "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = mlp(x3, transformer_units, drop_out, l2_weight)  # i *\n",
        "        encoded_patches = Add()([x3, x2])\n",
        "\n",
        "    x = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    #x = Concatenate()([x, demo])\n",
        "    features = mlp(x, mlp_head_units, 0.0, l2_weight)\n",
        "\n",
        "    logits = Dense(num_classes, kernel_regularizer=L2(l2_weight), bias_regularizer=L2(l2_weight),\n",
        "                   activation=activation)(features)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=logits)\n",
        "\n",
        "\n",
        "\n",
        "def create_hybrid_transformer_model(input_shape):\n",
        "    transformer_units =  [32,32]\n",
        "    transformer_layers = 2\n",
        "    num_heads = 4\n",
        "    l2_weight = 0.001\n",
        "    drop_out= 0.25\n",
        "    mlp_head_units = [256, 128]\n",
        "    num_patches=30\n",
        "    projection_dim=  32\n",
        "\n",
        "    # Conv1D(32...\n",
        "    input1 = Input(shape=input_shape)\n",
        "    conv11 = Conv1D(16, 256)(input1) #13\n",
        "    conv12 = Conv1D(16, 256)(input1) #13\n",
        "    conv13 = Conv1D(16, 256)(input1) #13\n",
        "\n",
        "    pwconv1 = SeparableConvolution1D(32, 1)(input1)\n",
        "    pwconv2 = SeparableConvolution1D(32, 1)(pwconv1)\n",
        "\n",
        "    conv21 = Conv1D(16, 256)(conv11) # 7\n",
        "    conv22 = Conv1D(16, 256)(conv12) # 7\n",
        "    conv23 = Conv1D(16, 256)(conv13) # 7\n",
        "\n",
        "    concat = keras.layers.concatenate([conv21, conv22, conv23], axis=-1)\n",
        "    concat = Dense(64, activation=relu)(concat) #192\n",
        "    concat = Dense(64, activation=sigmoid)(concat) #192\n",
        "    concat = SeparableConvolution1D(32,1)(concat)\n",
        "    concat = keras.layers.concatenate([concat, pwconv2], axis=1)\n",
        "\n",
        "    ####################################################################################################################\n",
        "    patch_size = input_shape[0] / num_patches\n",
        "\n",
        "    normalized_inputs = tfa.layers.InstanceNormalization(axis=-1, epsilon=1e-6, center=False, scale=False,\n",
        "                                                             beta_initializer=\"glorot_uniform\",\n",
        "                                                             gamma_initializer=\"glorot_uniform\")(concat)\n",
        "\n",
        "    # patches = Reshape((num_patches, -1))(normalized_inputs)\n",
        "    patches = Patches(patch_size=patch_size)(normalized_inputs)\n",
        "    encoded_patches = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim, l2_weight=l2_weight)(patches)\n",
        "    for i in range(transformer_layers):\n",
        "        x1 = encoded_patches # LayerNormalization(epsilon=1e-6)(encoded_patches) # TODO\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=drop_out, kernel_regularizer=L2(l2_weight),  # i *\n",
        "            bias_regularizer=L2(l2_weight))(x1, x1)\n",
        "        x2 = Add()([attention_output, encoded_patches])\n",
        "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = mlp(x3, transformer_units, drop_out, l2_weight)  # i *\n",
        "        encoded_patches = Add()([x3, x2])\n",
        "\n",
        "    x = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    #x = Concatenate()([x, demo])\n",
        "    features = mlp(x, mlp_head_units, 0.0, l2_weight)\n",
        "\n",
        "    logits = Dense(1, kernel_regularizer=L2(l2_weight), bias_regularizer=L2(l2_weight),\n",
        "                   activation='sigmoid')(features)\n",
        "\n",
        "    ####################################################################################################################\n",
        "\n",
        "    model = Model(inputs=input1, outputs=logits)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "gBdVZoTvsSFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c58dce1-8a9c-42a6-f884-5740d046a5c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selector"
      ],
      "metadata": {
        "id": "DNc-IoPsP1Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {\n",
        "    \"hybrid\": create_hybrid_transformer_model((60 * 32, 3)),\n",
        "}\n",
        "\n",
        "def get_model(config):\n",
        "    if config[\"model_name\"].split('_')[0] == \"Transformer\":\n",
        "        return create_transformer_model(input_shape=(3840, 17),\n",
        "                                        num_patches=config[\"num_patches\"], projection_dim=config[\"transformer_units\"],\n",
        "                                        transformer_layers=config[\"transformer_layers\"], num_heads=config[\"num_heads\"],\n",
        "                                        transformer_units=[config[\"transformer_units\"] * 2,\n",
        "                                                           config[\"transformer_units\"]],\n",
        "                                        mlp_head_units=[256, 128], num_classes=1, drop_out=config[\"drop_out_rate\"],\n",
        "                                        reg=config[\"regression\"], l2_weight=config[\"regularization_weight\"])\n",
        "    else:\n",
        "        return model_dict.get(config[\"model_name\"].split('_')[0])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config = {\n",
        "        \"model_name\": \"Transformer\",\n",
        "        \"regression\": False,\n",
        "\n",
        "        \"transformer_layers\": 4,  # best 5\n",
        "        \"drop_out_rate\": 0.25,\n",
        "        \"num_patches\": 20,  # best\n",
        "        \"transformer_units\": 32,  # best 32\n",
        "        \"regularization_weight\": 0.001,  # best 0.001\n",
        "        \"num_heads\": 4,\n",
        "        \"epochs\": 100,  # best\n",
        "        \"channels\": [14, 18, 19, 20],\n",
        "    }\n",
        "    model = get_model(config)\n",
        "    model.build(input_shape=(1, 60 * 32, 10))\n",
        "    print(model.summary())"
      ],
      "metadata": {
        "id": "TSgNHarbP4We",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f203ce46-3937-4589-cd85-3149516bf446"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 3840, 17)]           0         []                            \n",
            "                                                                                                  \n",
            " instance_normalization_1 (  (None, 3840, 17)             0         ['input_2[0][0]']             \n",
            " InstanceNormalization)                                                                           \n",
            "                                                                                                  \n",
            " patches_1 (Patches)         (None, None, 3264)           0         ['instance_normalization_1[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " patch_encoder_1 (PatchEnco  (None, None, 32)             104480    ['patches_1[0][0]']           \n",
            " der)                                                                                             \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, None, 32)             16800     ['patch_encoder_1[0][0]',     \n",
            " ltiHeadAttention)                                                   'patch_encoder_1[0][0]']     \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, None, 32)             0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'patch_encoder_1[0][0]']     \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, None, 32)             64        ['add_4[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, None, 64)             2112      ['layer_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.nn.gelu_6 (TFOpLambda)   (None, None, 64)             0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, None, 64)             0         ['tf.nn.gelu_6[0][0]']        \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, None, 32)             2080      ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " tf.nn.gelu_7 (TFOpLambda)   (None, None, 32)             0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, None, 32)             0         ['tf.nn.gelu_7[0][0]']        \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, None, 32)             0         ['dropout_7[0][0]',           \n",
            "                                                                     'add_4[0][0]']               \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, None, 32)             16800     ['add_5[0][0]',               \n",
            " ltiHeadAttention)                                                   'add_5[0][0]']               \n",
            "                                                                                                  \n",
            " add_6 (Add)                 (None, None, 32)             0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_5[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, None, 32)             64        ['add_6[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, None, 64)             2112      ['layer_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.nn.gelu_8 (TFOpLambda)   (None, None, 64)             0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, None, 64)             0         ['tf.nn.gelu_8[0][0]']        \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, None, 32)             2080      ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " tf.nn.gelu_9 (TFOpLambda)   (None, None, 32)             0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, None, 32)             0         ['tf.nn.gelu_9[0][0]']        \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, None, 32)             0         ['dropout_9[0][0]',           \n",
            "                                                                     'add_6[0][0]']               \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (Mu  (None, None, 32)             16800     ['add_7[0][0]',               \n",
            " ltiHeadAttention)                                                   'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, None, 32)             0         ['multi_head_attention_4[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, None, 32)             64        ['add_8[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, None, 64)             2112      ['layer_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.nn.gelu_10 (TFOpLambda)  (None, None, 64)             0         ['dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, None, 64)             0         ['tf.nn.gelu_10[0][0]']       \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, None, 32)             2080      ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " tf.nn.gelu_11 (TFOpLambda)  (None, None, 32)             0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, None, 32)             0         ['tf.nn.gelu_11[0][0]']       \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, None, 32)             0         ['dropout_11[0][0]',          \n",
            "                                                                     'add_8[0][0]']               \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (Mu  (None, None, 32)             16800     ['add_9[0][0]',               \n",
            " ltiHeadAttention)                                                   'add_9[0][0]']               \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, None, 32)             0         ['multi_head_attention_5[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_9[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, None, 32)             64        ['add_10[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, None, 64)             2112      ['layer_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " tf.nn.gelu_12 (TFOpLambda)  (None, None, 64)             0         ['dense_17[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, None, 64)             0         ['tf.nn.gelu_12[0][0]']       \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, None, 32)             2080      ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " tf.nn.gelu_13 (TFOpLambda)  (None, None, 32)             0         ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, None, 32)             0         ['tf.nn.gelu_13[0][0]']       \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, None, 32)             0         ['dropout_13[0][0]',          \n",
            "                                                                     'add_10[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_7 (Lay  (None, None, 32)             64        ['add_11[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1  (None, 32)                   0         ['layer_normalization_7[0][0]'\n",
            "  (GlobalAveragePooling1D)                                          ]                             \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 256)                  8448      ['global_average_pooling1d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " tf.nn.gelu_14 (TFOpLambda)  (None, 256)                  0         ['dense_19[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 256)                  0         ['tf.nn.gelu_14[0][0]']       \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 128)                  32896     ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " tf.nn.gelu_15 (TFOpLambda)  (None, 128)                  0         ['dense_20[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 128)                  0         ['tf.nn.gelu_15[0][0]']       \n",
            "                                                                                                  \n",
            " dense_21 (Dense)            (None, 1)                    129       ['dropout_15[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 230241 (899.38 KB)\n",
            "Trainable params: 230241 (899.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/Testing"
      ],
      "metadata": {
        "id": "18SlPEbQQBJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters: We did most of our training with the 4 default heads and for our ablations we set the number of heads to 1 and 8. We used a drop-out-rate of 0.25, and 5 transformer layers.\n",
        "\n",
        "Link to main training notebook: https://colab.research.google.com/drive/1uAEvpmUV9L8iUmS0NO5OhQRm6gh3ObjF?usp=sharing\n",
        "\n",
        "Computational Requirements: We trained using google colab, mainly using the TPU v2, which allocates us 336 GB of RAM. Whenever possible, we also made use of A100 GPUs, as they could complete training ~4x faster than the TPU. We used 100 epochs over 3 folds for each of the 20 signals. For trials, we trained using all five datasets and had a separate model for each. We performed trials using the default hyperparameters in the paper and then ran with 8 transformer heads and only 1 transformer head. Using TPU, it takes around 5 hours to train the model on one .npz file from the dataloader. Using the A100, it takes 1.5 hours to train on the same file."
      ],
      "metadata": {
        "id": "H1FARjT4VwhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score, average_precision_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Result:\n",
        "    def __init__(self):\n",
        "        self.accuracy_list = []\n",
        "        self.sensitivity_list = []\n",
        "        self.specificity_list = []\n",
        "        self.f1_list = []\n",
        "        self.auroc_list = []\n",
        "        self.auprc_list = []\n",
        "        self.precision_list = []\n",
        "\n",
        "    def add(self, y_test, y_predict, y_score):\n",
        "        C = confusion_matrix(y_test, y_predict, labels=(1, 0))\n",
        "        TP, TN, FP, FN = C[0, 0], C[1, 1], C[1, 0], C[0, 1]\n",
        "\n",
        "        acc, sn, sp, pr = 1. * (TP + TN) / (TP + TN + FP + FN), 1. * TP / (TP + FN), 1. * TN / (TN + FP), 1. * TP / (\n",
        "                TP + FP)\n",
        "        f1 = f1_score(y_test, y_predict)\n",
        "        auc = roc_auc_score(y_test, y_score)\n",
        "        auprc = average_precision_score(y_test, y_score)\n",
        "\n",
        "        self.accuracy_list.append(acc * 100)\n",
        "        self.precision_list.append(pr * 100)\n",
        "        self.sensitivity_list.append(sn * 100)\n",
        "        self.specificity_list.append(sp * 100)\n",
        "        self.f1_list.append(f1 * 100)\n",
        "        self.auroc_list.append(auc * 100)\n",
        "        self.auprc_list.append(auprc * 100)\n",
        "\n",
        "\n",
        "    def get(self, file_name):\n",
        "        out_str = \"=========================================================================== \\n\"\n",
        "        out_str += str(self.accuracy_list) + \" \\n\"\n",
        "        out_str += str(self.precision_list) + \" \\n\"\n",
        "        out_str += str(self.sensitivity_list) + \" \\n\"\n",
        "        out_str += str(self.specificity_list) + \" \\n\"\n",
        "        out_str += str(self.f1_list) + \" \\n\"\n",
        "        out_str += str(self.auroc_list) + \" \\n\"\n",
        "        out_str += str(self.auprc_list) + \" \\n\"\n",
        "        out_str += str(\"Accuracy: %.2f -+ %.3f\" % (np.mean(self.accuracy_list), np.std(self.accuracy_list))) + \" \\n\"\n",
        "        out_str += str(\"Precision: %.2f -+ %.3f\" % (np.mean(self.precision_list), np.std(self.precision_list))) + \" \\n\"\n",
        "        out_str += str(\n",
        "            \"Recall: %.2f -+ %.3f\" % (np.mean(self.sensitivity_list), np.std(self.sensitivity_list))) + \" \\n\"\n",
        "        out_str += str(\n",
        "            \"Specifity: %.2f -+ %.3f\" % (np.mean(self.specificity_list), np.std(self.specificity_list))) + \" \\n\"\n",
        "        out_str += str(\"F1: %.2f -+ %.3f\" % (np.mean(self.f1_list), np.std(self.f1_list))) + \" \\n\"\n",
        "        out_str += str(\"AUROC: %.2f -+ %.3f\" % (np.mean(self.auroc_list), np.std(self.auroc_list))) + \" \\n\"\n",
        "        out_str += str(\"AUPRC: %.2f -+ %.3f\" % (np.mean(self.auprc_list), np.std(self.auprc_list))) + \" \\n\"\n",
        "\n",
        "        out_str += str(\"$ %.1f \\pm %.1f$\" % (np.mean(self.accuracy_list), np.std(self.accuracy_list))) + \"& \"\n",
        "        out_str += str(\"$%.1f \\pm %.1f$\" % (np.mean(self.precision_list), np.std(self.precision_list))) + \"& \"\n",
        "        out_str += str(\"$%.1f \\pm %.1f$\" % (np.mean(self.sensitivity_list), np.std(self.sensitivity_list))) + \"& \"\n",
        "        out_str += str(\"$%.1f \\pm %.1f$\" % (np.mean(self.f1_list), np.std(self.f1_list))) + \"& \"\n",
        "        out_str += str(\"$%.1f \\pm %.1f$\" % (np.mean(self.auroc_list), np.std(self.auroc_list))) + \"& \"\n",
        "        with open(f\"{file_name}\", \"a\") as file:\n",
        "          file.write(out_str)\n",
        "\n",
        "        return out_str\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        plt.plot(self.auroc_list, label=\"AUROC\", marker='x')\n",
        "        plt.plot(self.f1_list, label=\"F1-Score\", marker='o')\n",
        "        plt.title(\"F1 Score and AUROC over time\")\n",
        "        plt.legend(loc=\"upper left\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Percentage\")\n",
        "        plt.show()\n",
        "\n",
        "    def print(self, file_name):\n",
        "        print(self.get(file_name))"
      ],
      "metadata": {
        "id": "gm-SZZQZ8UyQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras.metrics\n",
        "import numpy as np\n",
        "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "THRESHOLD = 1\n",
        "FOLD = 5\n",
        "\n",
        "#This function controls how the learning rate is\n",
        "#set based on the epoch\n",
        "def lr_schedule(epoch, lr):\n",
        "    if epoch > 50 and (epoch - 1) % 5 == 0:\n",
        "        lr *= 0.5\n",
        "    return lr\n",
        "\n",
        "#This is the train function we used\n",
        "#to replicate the results. We use\n",
        "#three splits of 100 epochs each to train\n",
        "#At the end of each split, part of the data\n",
        "#is used for testing\n",
        "def train(config, file_name):\n",
        "    data = np.load(config[\"data_path\"], allow_pickle=True)\n",
        "    x, y_apnea, y_hypopnea = data['x'], data['y_apnea'], data['y_hypopnea']\n",
        "    y = y_apnea + y_hypopnea\n",
        "    kf = KFold(n_splits=3)\n",
        "    kf.get_n_splits(x)\n",
        "    cnt = 0\n",
        "    result = Result()\n",
        "    for train_index, test_index in kf.split(x):\n",
        "        x_train, x_val = x[train_index], x[test_index]\n",
        "        y_train, y_val = y[train_index], y[test_index]\n",
        "        y_train[y_train > 0] = 1\n",
        "        y_val[y_val > 0] = 1\n",
        "        print(f'X Train Shape: {x_train.shape}')\n",
        "        model = get_model(config)\n",
        "        model.compile(optimizer=\"adam\", loss=BinaryCrossentropy(),\n",
        "                          metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "        early_stopper = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "        #training\n",
        "        model.fit(x=x_train, y=y_train, batch_size=512, epochs=config[\"epochs\"], verbose=\"None\", validation_split=0.1,\n",
        "                  callbacks=[early_stopper, lr_scheduler])\n",
        "\n",
        "        #testing\n",
        "        predict = model.predict(x_val)\n",
        "        y_score = predict\n",
        "        y_predict = np.where(predict > 0.5, 1, 0)\n",
        "        result.add(y_val, y_predict, y_score)\n",
        "        result.print(file_name)\n",
        "\n",
        "        model.save(config[\"model_path\"] + str(cnt))\n",
        "        keras.backend.clear_session()\n",
        "        cnt += 1\n",
        "\n",
        "#This function is used to train\n",
        "#one of our ablations (change the optimizer to SGD)\n",
        "def train_SGD(config, file_name):\n",
        "    data = np.load(config[\"data_path\"], allow_pickle=True)\n",
        "    x, y_apnea, y_hypopnea = data['x'], data['y_apnea'], data['y_hypopnea']\n",
        "    y = y_apnea + y_hypopnea\n",
        "    kf = KFold(n_splits=3)\n",
        "    kf.get_n_splits(x)\n",
        "    cnt = 0\n",
        "    result = Result()\n",
        "    for train_index, test_index in kf.split(x):\n",
        "        x_train, x_val = x[train_index], x[test_index]\n",
        "        y_train, y_val = y[train_index], y[test_index]\n",
        "        y_train[y_train > 0] = 1\n",
        "        y_val[y_val > 0] = 1\n",
        "        print(f'X Train Shape: {x_train.shape}')\n",
        "        model = get_model(config)\n",
        "        model.compile(optimizer=\"SGD\", loss=BinaryCrossentropy(),\n",
        "                          metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "        early_stopper = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "        #training\n",
        "        model.fit(x=x_train, y=y_train, batch_size=512, epochs=config[\"epochs\"], verbose=\"None\", validation_split=0.1,\n",
        "                  callbacks=[early_stopper, lr_scheduler])\n",
        "\n",
        "        #testing\n",
        "        predict = model.predict(x_val)\n",
        "        y_score = predict\n",
        "        y_predict = np.where(predict > 0.5, 1, 0)\n",
        "        result.add(y_val, y_predict, y_score)\n",
        "        result.print(file_name)\n",
        "\n",
        "        model.save(config[\"model_path\"] + str(cnt))\n",
        "        keras.backend.clear_session()\n",
        "        cnt += 1\n",
        "\n",
        "#This function is used to train one of\n",
        "#our ablations (change the optimizer to RMSProp)\n",
        "def train_RMSProp(config, file_name):\n",
        "    data = np.load(config[\"data_path\"], allow_pickle=True)\n",
        "    x, y_apnea, y_hypopnea = data['x'], data['y_apnea'], data['y_hypopnea']\n",
        "\n",
        "    y = y_apnea + y_hypopnea\n",
        "    kf = KFold(n_splits=3)\n",
        "    kf.get_n_splits(x)\n",
        "    cnt = 0\n",
        "    result = Result()\n",
        "    for train_index, test_index in kf.split(x):\n",
        "        x_train, x_val = x[train_index], x[test_index]\n",
        "        y_train, y_val = y[train_index], y[test_index]\n",
        "        y_train[y_train > 0] = 1\n",
        "        y_val[y_val > 0] = 1\n",
        "        print(f'X Train Shape: {x_train.shape}')\n",
        "        model = get_model(config)\n",
        "        model.compile(optimizer=\"RMSprop\", loss=BinaryCrossentropy(),\n",
        "                          metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "        early_stopper = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "        #training\n",
        "        model.fit(x=x_train, y=y_train, batch_size=512, epochs=config[\"epochs\"], verbose=\"None\", validation_split=0.1,\n",
        "                  callbacks=[early_stopper, lr_scheduler])\n",
        "\n",
        "        #testing\n",
        "        predict = model.predict(x_val)\n",
        "        y_score = predict\n",
        "        y_predict = np.where(predict > 0.5, 1, 0)\n",
        "        result.add(y_val, y_predict, y_score)\n",
        "        result.print(file_name)\n",
        "        model.save(config[\"model_path\"] + str(cnt))\n",
        "        keras.backend.clear_session()\n",
        "        cnt += 1"
      ],
      "metadata": {
        "id": "u1Q5Y6JGQEQE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CHAT Training"
      ],
      "metadata": {
        "id": "3cL914q3Q6vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combinations of signals on the DataLoader_0.npz file\n",
        "#Training/Testing Results for DataLoader_0 using Three Signals (EOG, EEG. Resp)\n",
        "#This is the full list of 20 signals we used to train the model. In order to provide a\n",
        "#sample of the training, we provided a sample list called example_list_chat.\n",
        "channel_list_chat = [\n",
        "    [\"EOG\", \"EEG\", \"ECG\"],\n",
        "    [\"EOG\",\"EEG\", \"Resp\"],\n",
        "    [\"EOG\", \"EEG\", \"SPO2\"],\n",
        "    [\"EOG\",\"EEG\", \"CO2\"],\n",
        "    [\"EOG\", \"ECG\", \"Resp\"],\n",
        "    [\"EOG\",\"ECG\", \"SPO2\"],\n",
        "    [\"EOG\", \"ECG\", \"CO2\"],\n",
        "    [\"EOG\",\"Resp\", \"SPO2\"],\n",
        "    [\"EOG\", \"Resp\", \"CO2\"],\n",
        "    [\"EOG\",\"SPO2\", \"CO2\"],\n",
        "    [\"EEG\", \"ECG\", \"Resp\"],\n",
        "    [\"EEG\",\"ECG\", \"SPO2\"],\n",
        "    [\"EEG\", \"ECG\", \"CO2\"],\n",
        "    [\"EEG\",\"Resp\", \"SPO2\"],\n",
        "    [\"EEG\", \"Resp\", \"CO2\"],\n",
        "    [\"EEG\",\"SPO2\", \"CO2\"],\n",
        "    [\"ECG\", \"Resp\", \"SPO2\"],\n",
        "    [\"ECG\",\"Resp\", \"CO2\"],\n",
        "    [\"ECG\", \"SPO2\", \"CO2\"],\n",
        "    [\"Resp\",\"SPO2\", \"CO2\"],\n",
        "\n",
        "]\n",
        "\n",
        "example_list_chat = [\n",
        "  [\"ECG\", \"SPO2\", \"CO2\"]\n",
        "]\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}"
      ],
      "metadata": {
        "id": "fvrOYdWTPthC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training/Testing Results for DataLoader_1\n",
        "#This is using the shorter example_list_chat to provide an example of our training\n",
        "for ch_lst in example_list_chat:\n",
        "    print(f'-------------------Channel List: {ch_lst}-------------------')\n",
        "    with open(\"transformer_metrics_dataloader_sample.txt\", \"a\") as file:\n",
        "        file.write(f'-------------------Channel List: {ch_lst}-------------------\\n')\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch_lst:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": \"/content/drive/My Drive/DL4H - Final Project/dataloader_output_1.npz\", #change to the files in dataloader\n",
        "        \"model_path\": \"/content/drive/My Drive/Colab Notebooks/CS_598_Proj/Model_Folder\",\n",
        "        \"model_name\": \"Transformer_\"+ chstr,\n",
        "        \"regression\": False,\n",
        "        \"transformer_layers\": 5,  # best 5\n",
        "        \"drop_out_rate\": 0.25,  # best 0.25\n",
        "        \"num_patches\": 30,  # best 30 TBD\n",
        "        \"transformer_units\": 32,  # best 32\n",
        "        \"regularization_weight\": 0.001,  # best 0.001\n",
        "        \"num_heads\": 4,\n",
        "        \"epochs\": 100,  # best 200\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    train(config, \"transformer_metrics_dataloader_sample.txt\") #We store our metrics in these text files and post-process them to generate plots"
      ],
      "metadata": {
        "id": "dGsPl7yeEGMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ff13c0-2bf2-43dd-e5f1-99dd82e2fdbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------Channel List: ['ECG', 'SPO2', 'CO2']-------------------\n",
            "ECGSPO2CO2 [15, 16, 13, 14]\n",
            "X Train Shape: (6522, 3840, 17)\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 2s 9ms/step\n",
            "=========================================================================== \n",
            "[71.98038013488657] \n",
            "[65.29209621993127] \n",
            "[93.4809348093481] \n",
            "[50.61124694376527] \n",
            "[76.8841679312089] \n",
            "[81.82609836489564] \n",
            "[77.18088457288631] \n",
            "Accuracy: 71.98 -+ 0.000 \n",
            "Precision: 65.29 -+ 0.000 \n",
            "Recall: 93.48 -+ 0.000 \n",
            "Specifity: 50.61 -+ 0.000 \n",
            "F1: 76.88 -+ 0.000 \n",
            "AUROC: 81.83 -+ 0.000 \n",
            "AUPRC: 77.18 -+ 0.000 \n",
            "$ 72.0 \\pm 0.0$& $65.3 \\pm 0.0$& $93.5 \\pm 0.0$& $76.9 \\pm 0.0$& $81.8 \\pm 0.0$& \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7cbc743eb0a0>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Shape: (6523, 3840, 17)\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "Epoch 32/100\n",
            "Epoch 33/100\n",
            "Epoch 34/100\n",
            "Epoch 35/100\n",
            "Epoch 36/100\n",
            "Epoch 37/100\n",
            "Epoch 38/100\n",
            "Epoch 39/100\n",
            "Epoch 40/100\n",
            "Epoch 41/100\n",
            "Epoch 42/100\n",
            "Epoch 43/100\n",
            "Epoch 44/100\n",
            "Epoch 45/100\n",
            "Epoch 46/100\n",
            "Epoch 47/100\n",
            "Epoch 48/100\n",
            "Epoch 49/100\n",
            "Epoch 50/100\n",
            "Epoch 51/100\n",
            "Epoch 52/100\n",
            "Epoch 53/100\n",
            "Epoch 54/100\n",
            "Epoch 55/100\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 2s 9ms/step\n",
            "=========================================================================== \n",
            "[71.98038013488657, 74.94633547991414] \n",
            "[65.29209621993127, 70.73417721518987] \n",
            "[93.4809348093481, 85.39119804400977] \n",
            "[50.61124694376527, 64.43076923076923] \n",
            "[76.8841679312089, 77.37468845195237] \n",
            "[81.82609836489564, 81.4931164190333] \n",
            "[77.18088457288631, 77.30055809397881] \n",
            "Accuracy: 73.46 -+ 1.483 \n",
            "Precision: 68.01 -+ 2.721 \n",
            "Recall: 89.44 -+ 4.045 \n",
            "Specifity: 57.52 -+ 6.910 \n",
            "F1: 77.13 -+ 0.245 \n",
            "AUROC: 81.66 -+ 0.166 \n",
            "AUPRC: 77.24 -+ 0.060 \n",
            "$ 73.5 \\pm 1.5$& $68.0 \\pm 2.7$& $89.4 \\pm 4.0$& $77.1 \\pm 0.2$& $81.7 \\pm 0.2$& \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7cbc50414790>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train Shape: (6523, 3840, 17)\n",
            "Epoch 1/100\n",
            "Epoch 2/100\n",
            "Epoch 3/100\n",
            "Epoch 4/100\n",
            "Epoch 5/100\n",
            "Epoch 6/100\n",
            "Epoch 7/100\n",
            "Epoch 8/100\n",
            "Epoch 9/100\n",
            "Epoch 10/100\n",
            "Epoch 11/100\n",
            "Epoch 12/100\n",
            "Epoch 13/100\n",
            "Epoch 14/100\n",
            "Epoch 15/100\n",
            "Epoch 16/100\n",
            "Epoch 17/100\n",
            "Epoch 18/100\n",
            "Epoch 19/100\n",
            "Epoch 20/100\n",
            "Epoch 21/100\n",
            "Epoch 22/100\n",
            "Epoch 23/100\n",
            "Epoch 24/100\n",
            "Epoch 25/100\n",
            "Epoch 26/100\n",
            "Epoch 27/100\n",
            "Epoch 28/100\n",
            "Epoch 29/100\n",
            "Epoch 30/100\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 2s 9ms/step\n",
            "=========================================================================== \n",
            "[71.98038013488657, 74.94633547991414, 72.73842379638148] \n",
            "[65.29209621993127, 70.73417721518987, 70.69716775599129] \n",
            "[93.4809348093481, 85.39119804400977, 78.7143723468769] \n",
            "[50.61124694376527, 64.43076923076923, 66.62531017369727] \n",
            "[76.8841679312089, 77.37468845195237, 74.4906743185079] \n",
            "[81.82609836489564, 81.4931164190333, 80.56672440023054] \n",
            "[77.18088457288631, 77.30055809397881, 77.5203521596197] \n",
            "Accuracy: 73.22 -+ 1.258 \n",
            "Precision: 68.91 -+ 2.557 \n",
            "Recall: 85.86 -+ 6.038 \n",
            "Specifity: 60.56 -+ 7.089 \n",
            "F1: 76.25 -+ 1.260 \n",
            "AUROC: 81.30 -+ 0.533 \n",
            "AUPRC: 77.33 -+ 0.141 \n",
            "$ 73.2 \\pm 1.3$& $68.9 \\pm 2.6$& $85.9 \\pm 6.0$& $76.2 \\pm 1.3$& $81.3 \\pm 0.5$& \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7cbc3290fb20>, because it is not built.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Metrics\n"
      ],
      "metadata": {
        "id": "C3YKy9eJY7c6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used the F1-score and the AUROC for a set of three of the channels. We did this for all permutations. For example, we would run using [EEG, ECG, Resp] and then in the next iteration train using [EEG, Resp, SPO2]."
      ],
      "metadata": {
        "id": "1qVB1TrwZHvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "\n",
        "\n",
        "We ran the testing using a set of 453 files. These files were then fed into a dataloader which aggregated the results into 5 .npz files. We then fed these five files into our train/test split code, in which we ran 3 folds with 100 epochs per fold. After running this, we got the following results:\n",
        "\n",
        "|Signal Name|     AUROC  |    F1_Score|\n",
        "|--|--|--|\n",
        "|EOG_EEG_ECG  |  82.373220  |76.954192|\n",
        "|EOG_EEG_Resp |  82.085724  |76.361555|\n",
        "EOG_EEG_SPO2  | 82.150691  |77.017589|\n",
        "EOG_EEG_CO2    |81.980204  |76.553642|\n",
        "EOG_ECG_Resp   |82.145661  |76.532950|\n",
        "EOG_ECG_SPO2   |82.339140  |77.102860|\n",
        "EOG_ECG_CO2    |81.984646  |76.611582|\n",
        "EOG_Resp_SPO2  |81.496857  |76.292230|\n",
        "EOG_Resp_CO2   |82.199853  |76.812138|\n",
        "EOG_SPO2_CO2   |81.910237  |76.557044|\n",
        "EEG_ECG_Resp   |82.715152 |76.884725|\n",
        "EEG_ECG_SPO2   |82.156777  |76.826285|\n",
        "EEG_ECG_CO2    |81.875676  |76.290632|\n",
        "EEG_Resp_SPO2  |81.888109  |76.488260|\n",
        "EEG_Resp_CO2   |81.726037  |76.709073|\n",
        "EEG_SPO2_CO2   |81.834320  |76.533486|\n",
        "ECG_Resp_SPO2  |81.610316  |76.400942|\n",
        "ECG_Resp_CO2   |81.944396  |76.606034|\n",
        "ECG_SPO2_CO2   |82.185297  |76.470580|\n",
        "Resp_SPO2_CO2  |81.764528  |76.606435|\n",
        "\n",
        " The hypothesis we were testing is that it is possible to detect Obstructive Sleep apnea hypopnea Syndrome (OSAHS) in pediatric patients with PSG-level performance in adults. We achieved this as we got similar results to the paperOn average with our results being around 5 - 6 % lower than the F1 and AUROC values present in the original paper.\n",
        "\n",
        "The below results are the results from the actual paper using different signals, the actual model can perform well on just two signals: EEG and SpO2\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1aJDfBQgsNvpk2d1i2HA8voSyBJtyMLZm)\n",
        "\n",
        "We did not perform any additional experiments and just focused on replicating the research paper.\n",
        "\n",
        "##  Ablation Study:\n",
        "\n",
        "We used the ['EOG', 'ECG', 'SPO2'] signal as it was the highest performing signal in the paper for all of these ablation studies.\n",
        "\n",
        "|Ablation Tested|  AUROC  |    F1_Score|\n",
        "|--|--|--|\n",
        "|Single-Head Attention |  82.31775  |76.54671|\n",
        "|Multi-Head Attention |  81.740597  |76.249381|\n",
        "|SGD optimizer |  72.48160  |75.09215|   \n",
        "| RMSProp optimizer| 82.76525| 71.83191|\n",
        "\n",
        "For the ablation study, we modified the number of transformer heads and changed the optimizer used during training. When changing the number of heads, there weren't significant changes in the metrics, but the metrics for single-head and using 8 heads were slightly lower than the score we got using 4-head attention (82.339140). When using the SGD optimizer, we noticed that both the F1 and the AUROC were far lower than with the default Adam optimizer. The RMSProp achieved similar AUROC, but resulted in a lower F1-Score.\n",
        "\n",
        "Link to Plotting and Metrics Aggregation Notebook:\n",
        "https://colab.research.google.com/drive/1_KabQX9RbDNArACSyeren3J6WRgWp0LW?usp=sharing\n",
        "\n",
        "Link to Plotting Folder:\n",
        "https://drive.google.com/drive/folders/1OtzZoxa24jiOQ_xCvGQ1AIyYVLwHW8zs?usp=sharing"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison\n",
        "\n",
        "Compared to the other models and the original model in the paper, the AUROC and the F1-score that our implementation has is significantly lower. The AUROC score that we had in our second fold was 81.42, while the paper implementation had an AUROC of 90. Our model is comparable to the other architectures, such as the SE-MSCNN which has an AUROC of 82.6. Using a greater number of epochs and training the model for longer can help us to increase our scores."
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "  The paper was reproducible, but signifcant changes needed to be made to the code because the code is not very well documented. Training/testing was also challenging because a lot of resources (e.g. GPU, TPU) needs to be used to optimize training/testing the large dataset.\n",
        "\n",
        "  During the training process, we chose to use the CHAT dataset instead of the NCH dataset because it is 5 times smaller (~400 gb VS. 2 TB).\n",
        "\n",
        "  Furthermore, there is little to no comments in the code, so it is very difficult to understand how or why certain functions are being used. For example, in the train.py, there are multiple variables declared for the number of folds to use for cross-fold validation, there is a lowercase fold variable that is used in several locations in addition to an upppercase FOLD variable that is used as well. In this case, it doesn't make sense which fold/FOLD variable is getting used, as both are called seemingly interchangeably across the code.\n",
        "\n",
        "  It was easy to get data access, as the NSRR organization responded within a week to our request. Setting up the data processing pipeline was not too difficult, as colab enabled us to use GPUs and TPU to parse through the files.The file downloading process was also easy because the NSRR repo contained clear documentation for how to use a Ruby script to download the files.\n",
        "\n",
        "  Training the dataset and debugging the data processing has been our biggest difficulty. We only ran with CHAT because it was taking a long time to setup and train the entire dataset. Using TPU it takes over 4 hours per file, and on GPU, it takes around 1.5 hours per file. We were able to get the training and testing to work by using a different training/testing method (scikit-learn KFold) instead of the given cross-validation and by reshaping the input layer.\n",
        "\n",
        "  The authors need to include significantly more documentation in the Github. There are no comments in any of the python files, so the team had to spend a lot of time reading the code to try and get an understanding. The readme file only discusses the research paper and does not mention anything about the code. It should be updated to provide at least a short description of what each of the files are doing. A requirements.txt should also be added, because we had no idea what libraries the original authors used in their implementation. The team was running into errors with the mne library because the latest version that we used did not work with the data. We needed to revert to an older version to get the preprocessing script to work.  \n",
        "\n"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "Hung-Yu Chang, Cheng-Yu Yeh, Chung-Te Lee, and Chun-Cheng Lin. A sleep apnea\n",
        " detection system based on a one-dimensional deep convolution neural network model\n",
        " using single-lead electrocardiogram. Sensors, 20(15):4157, 2020.\n",
        "\n",
        " Xianhui Chen, Ying Chen, Wenjun Ma, Xiaomao Fan, and Ye Li. Toward sleep apnea\n",
        " detection with lightweight multi-scaled fusion network. Knowledge-Based Systems, 247:\n",
        " 108783, 2022.\n",
        "\n",
        " Asghar Zarei, Hossein Beheshti, and Babak Mohammadzadeh Asl. Detection of sleep apnea\n",
        " using deep neural networks and single-lead ecg signals. Biomedical Signal Processing\n",
        " and Control, 71:103125, 2022.\n",
        "\n",
        " Shuaicong Hu, Wenjie Cai, Tijie Gao, and Mingjie Wang. A hybrid transformer model for\n",
        " obstructive sleep apnea detection based on self-attention mechanism using single-lead\n",
        " ecg. IEEE Transactions on Instrumentation and Measurement, 71:1–11, 2022.\n",
        "\n",
        " Harlin Lee and Aaqib Saeed. Pediatric sleep scoring in-the-wild from millions of multi channel\n",
        " eeg signals. arXiv preprint arXiv:2207.06921, 2022.\n",
        "\n",
        " Zhang, G. Q., Cui, L., Mueller, R., Tao, S., Kim, M., Rueschman, M., Mariani, S., Mobley, D., &\n",
        " Redline, S. 2024. The National Sleep Research Resource: Towards a sleep data\n",
        " commons\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_X_7V5YOnjr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}